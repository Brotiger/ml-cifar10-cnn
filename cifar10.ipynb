{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Сверточная нейросеть для решения задачи классификации картинок","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import datasets, transforms\n\ndata_tfs = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5), (0.5))\n])\n\ntrain_data = datasets.CIFAR10(root='/kaggle/working/cifar10_data', train=True, download=True, transform=data_tfs)\ntest_data = datasets.CIFAR10(root='/kaggle/working/cifar10_data', train=False, download=True, transform=data_tfs)\n\ntrain_data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T17:22:16.355423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(len(train_data) * 0.8)\nval_size = len(train_data) - train_size\n\ntrain_data, val_data = torch.utils.data.random_split(train_data, [train_size, val_size])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=True)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False, pin_memory=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(train_loader))\nimages.shape, labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(images, labels):\n    f, axes = plt.subplots(1, 10, figsize=(30, 5))\n    \n    for i, axis in enumerate(axes):\n        img = images[i].numpy()\n        img = np.transpose(img, (1, 2, 0))\n        \n        axes[i].imshow(img)\n        axes[i].set_title(labels[i].numpy())\n        \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(images, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# моудль где определены слои для нейронной сети\nimport torch.nn as nn\n# модуль где определены функции активации\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1) #32x32\n        self.pool1 = nn.MaxPool2d(kernel_size=(2,2)) #16x16\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1) #16x16\n        self.pool2 = nn.MaxPool2d(kernel_size=(2,2)) #8x8\n        self.flatten = nn.Flatten()\n        \n        self.fc1 = nn.Linear(8 * 8 * 32, 1024)\n        self.fc2 = nn.Linear(1024, 1024)\n        self.fc3 = nn.Linear(1024, 10)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        \n        x = self.flatten(x)\n        \n        x = F.elu(self.fc1(x))\n        x = F.elu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_net = ConvNet()\nconv_net = conv_net.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = torch.nn.CrossEntropyLoss()\nlearning_rate = 1e-3\noptimizer = torch.optim.Adam(conv_net.parameters(), lr=learning_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, dataloader, loss_fn):\n    losses = []\n    num_correct = 0\n    num_elements = len(dataloader)\n    \n    for i, batch in enumerate(dataloader):\n        X_batch, y_batch = batch\n        X_batch = X_batch.to(device)\n        y_batch = y_batch.to(device)\n        \n        with torch.no_grad():\n            logits = model(X_batch)\n            \n            loss = loss_fn(logits, y_batch)\n            losses.append(loss.item())\n            \n            y_pred = torch.argmax(logits, dim=1)\n            num_correct += torch.sum(y_pred == y_batch)\n    \n    accuracy = num_correct / num_elements\n    \n    return accuracy, np.mean(losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output\n\ndef train(model, loss_fn, optimizer, n_epoch=3):\n    train_losses = []\n    train_accuracies = []\n    \n    val_losses = []\n    val_accuracies = []\n    \n    for epoch in range(n_epoch):\n        model.train(True)\n        \n        for i, batch in enumerate(train_loader):\n            X_batch, y_batch = batch\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            \n            logits = model(X_batch)\n            \n            loss = loss_fn(logits, y_batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            if i % 50 == 0:\n                fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n                train_losses.append(loss.item())\n                \n                model_answers = torch.argmax(logits, dim=1)\n                train_accuracy = accuracy_score(y_batch.numpy(), model_answers)\n                train_accuracies.append(train_accuracy)\n                \n                train_iterations = np.array(range(len(train_losses)))*50\n                \n                axes[0, 0].plot(train_iterations, train_losses)\n                axes[0, 0].set_title('Train losses')\n                axes[0, 0].set(xlabel='Iterations', ylabel='Loss')\n                \n                axes[0, 1].plot(train_iterations, train_accuracies)\n                axes[0, 1].set_title('Train accuracies')\n                axes[0, 1].set(xlabel='Iterations', ylabel='Accuracy')\n                \n                val_iterations = np.array(range(len(val_losses)))*50\n                \n                axes[1, 0].plot(val_iterations, val_losses)\n                axes[1, 0].set_title('Val losses')\n                axes[1, 0].set(xlabel='Iterations', ylabel='Loss')\n                \n                axes[1, 1].plot(val_iterations, val_accuracies)\n                axes[1, 1].set_title('Val accuracies')\n                axes[1, 1].set(xlabel='Iterations', ylabel='Accuracy')\n                \n                plt.show()\n                \n                clear_output(wait=True)\n            \n        model.train(False)\n        \n        val_accuracy, val_loss = evaluate(model, val_loader, loss_fn=loss_fn)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n        \n    return model, train_losses, val_losses, val_accuracies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_net, train_losses_conv, val_losses_conv, val_accuracies_conv = train(conv_net, loss_fn, optimizer, n_epoch=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.title('Train losses')\nplt.plot(np.arange(len(train_losses_conv)), train_losses_conv, label='train losses')\nplt.plot(np.arange(1, len(val_losses_conv) + 1) * (len(train_losses_conv) // len(val_losses_conv)), val_losses_conv, label='val losses')\nplt.scatter(np.arange(1, len(val_losses_conv) + 1) * (len(train_losses_conv) // len(val_losses_conv)), val_losses_conv, label='val losses')\nplt.xlabel('number of iterations')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.title('Val accuracies')\nplt.plot(np.arange(len(val_accuracies_conv)), val_accuracies_conv, label='val accuracies')\nplt.xlabel('number of iterations')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_accuracy, _ = evaluate(conv_net, train_loader, loss_fn)\nprint(f'Train accuracy: {train_accuracy}')\n\ntest_accuracy, _ = evaluate(conv_net, test_loader, loss_fn)\nprint(f'Test accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}